# Neural Machine Translation by Jointly Learning to Align and Translate
[Link](https://arxiv.org/abs/1409.0473)

## 1) Summary
The model should be free of assumptions about specific hardcoded template, rules or categories and instead rely on learning from the training data.
We evaluated its performance on both fullframe and region level experiments and showed that in both cases the Multimodal RNN ouperforms retrival baselines.

Our core insight is that we can leverage these large image sentence datasets by treating the sentences as weak labels, in which contiguous segments of words correspond to some particular, but unknow location in the image.


## 2) Evalution
 1. Novle Idea => Normal
 2. Good Motivation => Good
 3. Easy to Read => Good
 4. Reproducible => --
 5. Convincing results => Good

  - Points in favor
    1. Use the CNN and RNN together
    
