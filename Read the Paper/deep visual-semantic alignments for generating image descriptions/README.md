## Deep Visual-Semantic Alignments for Generating Image Descriptions
### [Link](https://arxiv.org/abs/1412.2306)

1) Summary
  The model should be free of assumptions about specific hardcoded templates, rules or categories and instead rely on learning from the training data.
 We evaluated its performance on both fullframe and region-level experiments and showed that in both cases the Multimodel RNN outperforms
 retrieval baselines. Our core insight is that we can leverage these large image sentence datasets by treating the senteces as weak labels,
 in which contoguous segments of words correspond to some particular, but unknown location in the image.
 
2) Evaluation
 1. Novel Idea => Normal
 2. Good Motivation => Good
 3. Easy to Read => GOood
 4. Reproducible => --
 5. Convincing Results => Good
 
 - Points in favor.
  1. Use the CNN model and RNN model together is novelty idea.
